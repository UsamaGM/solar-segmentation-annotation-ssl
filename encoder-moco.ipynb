{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3d4b76",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:05.675254Z",
     "iopub.status.busy": "2025-10-26T20:50:05.674467Z",
     "iopub.status.idle": "2025-10-26T20:50:14.297404Z",
     "shell.execute_reply": "2025-10-26T20:50:14.296528Z"
    },
    "papermill": {
     "duration": 8.629561,
     "end_time": "2025-10-26T20:50:14.298925",
     "exception": false,
     "start_time": "2025-10-26T20:50:05.669364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b955e7c3",
   "metadata": {
    "papermill": {
     "duration": 0.002893,
     "end_time": "2025-10-26T20:50:14.305396",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.302503",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 1 - Dataset Augmentation for SimCLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2097d7eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.312475Z",
     "iopub.status.busy": "2025-10-26T20:50:14.312117Z",
     "iopub.status.idle": "2025-10-26T20:50:14.320056Z",
     "shell.execute_reply": "2025-10-26T20:50:14.319521Z"
    },
    "papermill": {
     "duration": 0.012835,
     "end_time": "2025-10-26T20:50:14.321250",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.308415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimCLRDataTransform:\n",
    "    \"\"\"\n",
    "    Yeh transform class ek image leti hai aur uske do augmented versions (views) return karti hai.\n",
    "    \"\"\"\n",
    "    def __init__(self, image_size=128):\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(size=image_size, scale=(0.5, 1.0)),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomVerticalFlip(p=0.5),\n",
    "            # Color jitter SimCLR ke liye bahut zaroori hai\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.2, hue=0.1),\n",
    "            transforms.RandomGrayscale(p=0.2),\n",
    "            transforms.GaussianBlur(kernel_size=23, sigma=(0.1, 2.0)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "\n",
    "    def __call__(self, image):\n",
    "        # Ek hi image par do baar alag-alag transform apply karein\n",
    "        view_1 = self.transform(image)\n",
    "        view_2 = self.transform(image)\n",
    "        return view_1, view_2\n",
    "\n",
    "class SatelliteImageDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Loads the FULL satellite images.\n",
    "    The SimCLR transform will handle the random cropping (tiling).\n",
    "    \"\"\"\n",
    "    def __init__(self, image_dir, transform):\n",
    "        self.image_dir = image_dir\n",
    "        # Just get a list of all image paths\n",
    "        self.image_files = []\n",
    "        for f in os.listdir(image_dir):\n",
    "            if f.endswith(('.png', '.jpg', '.jpeg')):\n",
    "                self.image_files.append(os.path.join(image_dir, f))\n",
    "                \n",
    "        self.transform = transform\n",
    "        \n",
    "        print(f\"Dataset created with {len(self.image_files)} images.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        # The length is just the number of images\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_files[idx]\n",
    "        \n",
    "        try:\n",
    "            # Open the full image\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            \n",
    "            # Apply the SimCLR transform (which returns view_1, view_2)\n",
    "            # The transform's RandomResizedCrop will create the \"tile\"\n",
    "            return self.transform(image)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            # Fallback: get a different random image\n",
    "            random_idx = random.randint(0, len(self)-1)\n",
    "            return self.__getitem__(random_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b60e6985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.328135Z",
     "iopub.status.busy": "2025-10-26T20:50:14.327713Z",
     "iopub.status.idle": "2025-10-26T20:50:14.330988Z",
     "shell.execute_reply": "2025-10-26T20:50:14.330294Z"
    },
    "papermill": {
     "duration": 0.00806,
     "end_time": "2025-10-26T20:50:14.332285",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.324225",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "DATA_DIR = \"/kaggle/input/solar-dataset/Dataset/\"\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0790fd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.338840Z",
     "iopub.status.busy": "2025-10-26T20:50:14.338632Z",
     "iopub.status.idle": "2025-10-26T20:50:14.785983Z",
     "shell.execute_reply": "2025-10-26T20:50:14.785138Z"
    },
    "papermill": {
     "duration": 0.452087,
     "end_time": "2025-10-26T20:50:14.787347",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.335260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset created with 2516 images.\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the transform\n",
    "# This transform *is* your tiling logic\n",
    "transform = SimCLRDataTransform(image_size=IMAGE_SIZE)\n",
    "\n",
    "# 2. Create the Dataset (with the simplified class)\n",
    "dataset = SatelliteImageDataset(image_dir=DATA_DIR, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65099b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.794836Z",
     "iopub.status.busy": "2025-10-26T20:50:14.794601Z",
     "iopub.status.idle": "2025-10-26T20:50:14.801752Z",
     "shell.execute_reply": "2025-10-26T20:50:14.801080Z"
    },
    "papermill": {
     "duration": 0.012105,
     "end_time": "2025-10-26T20:50:14.802820",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.790715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split: 2264 train, 252 val\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.9*len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 3. Create the DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_ds,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "print(f\"Data split: {len(train_ds)} train, {len(val_ds)} val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8793072a",
   "metadata": {
    "papermill": {
     "duration": 0.002856,
     "end_time": "2025-10-26T20:50:14.809098",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.806242",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Step 2 - SimCLR Model aur Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd29c776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.816119Z",
     "iopub.status.busy": "2025-10-26T20:50:14.815640Z",
     "iopub.status.idle": "2025-10-26T20:50:14.819379Z",
     "shell.execute_reply": "2025-10-26T20:50:14.818637Z"
    },
    "papermill": {
     "duration": 0.00829,
     "end_time": "2025-10-26T20:50:14.820477",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.812187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.models import resnet50\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e6e3b55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.827312Z",
     "iopub.status.busy": "2025-10-26T20:50:14.827077Z",
     "iopub.status.idle": "2025-10-26T20:50:14.831737Z",
     "shell.execute_reply": "2025-10-26T20:50:14.831199Z"
    },
    "papermill": {
     "duration": 0.009129,
     "end_time": "2025-10-26T20:50:14.832696",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.823567",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class EncoderProjector(nn.Module):\n",
    "    \"\"\"\n",
    "    1. Encoder (Backbone): ResNet-50.\n",
    "    2. Projection Head: MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self, encoder_output_dim=2048, projection_dim=128):\n",
    "        super(EncoderProjector, self).__init__()\n",
    "        \n",
    "        # 1. Encoder (ResNet-50)\n",
    "        self.encoder = resnet50(weights='DEFAULT')\n",
    "        num_features = self.encoder.fc.in_features\n",
    "        self.encoder.fc = nn.Identity() # Aakhri layer hata di\n",
    "        \n",
    "        # 2. Projection Head (g)\n",
    "        self.projector = nn.Sequential(\n",
    "            nn.Linear(num_features, num_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_features, projection_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.encoder(x)\n",
    "        projections = self.projector(features)\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a5ee398",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.839746Z",
     "iopub.status.busy": "2025-10-26T20:50:14.839534Z",
     "iopub.status.idle": "2025-10-26T20:50:14.848481Z",
     "shell.execute_reply": "2025-10-26T20:50:14.847913Z"
    },
    "papermill": {
     "duration": 0.013894,
     "end_time": "2025-10-26T20:50:14.849574",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.835680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MoCo(nn.Module):\n",
    "    \"\"\"\n",
    "    MoCo (Momentum Contrast) implementation.\n",
    "    Yeh queue aur ek momentum encoder (encoder_k) istemal karta hai.\n",
    "    \"\"\"\n",
    "    def __init__(self, base_encoder_cls, dim=128, K=4096, m=0.999, T=0.07):\n",
    "        \"\"\"\n",
    "        dim: feature dimension (aapka PROJECTION_DIM)\n",
    "        K: queue size (kitne negative samples store karne hain)\n",
    "        m: momentum (key encoder ko update karne ke liye)\n",
    "        T: temperature\n",
    "        base_encoder_cls: Aapki 'EncoderProjector' class\n",
    "        \"\"\"\n",
    "        super(MoCo, self).__init__()\n",
    "\n",
    "        self.K = K\n",
    "        self.m = m\n",
    "        self.T = T\n",
    "\n",
    "        # Do encoders banayein: query aur key\n",
    "        self.encoder_q = base_encoder_cls(projection_dim=dim)\n",
    "        self.encoder_k = base_encoder_cls(projection_dim=dim)\n",
    "\n",
    "        # Key encoder (encoder_k) ke parameters ko copy karein\n",
    "        # Aur key encoder ke liye gradient calculation band kar dein\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)\n",
    "            param_k.requires_grad = False\n",
    "\n",
    "        # Negative samples ki queue banayein\n",
    "        # 'register_buffer' istemal hota hai takeh yeh model state ka hissa ho,\n",
    "        # lekin optimizer isse update na kare\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = F.normalize(self.queue, dim=0)\n",
    "        \n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        \"\"\"\n",
    "        Key encoder ko slowly update karein (momentum update)\n",
    "        encoder_k = m * encoder_k + (1-m) * encoder_q\n",
    "        \"\"\"\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1.0 - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        # 'keys' current batch ke keys hain (shape: [B, dim])\n",
    "        batch_size = keys.shape[0]\n",
    "        ptr = int(self.queue_ptr)\n",
    "        \n",
    "        # Queue mein naye keys daalein\n",
    "        self.queue[:, ptr : ptr + batch_size] = keys.T\n",
    "        \n",
    "        # Pointer ko aage badhayein\n",
    "        ptr = (ptr + batch_size) % self.K\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    def forward(self, im_q, im_k):\n",
    "        \"\"\"\n",
    "        Input:\n",
    "        im_q: view 1 ka batch (query)\n",
    "        im_k: view 2 ka batch (key)\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. Query features compute karein (gradients ke saath)\n",
    "        q = self.encoder_q(im_q) # Shape: [B, dim]\n",
    "        q = F.normalize(q, dim=1) # Normalize\n",
    "\n",
    "        # 2. Key features compute karein (gradients nahi chahiye)\n",
    "        with torch.no_grad():\n",
    "            self._momentum_update_key_encoder() # Key encoder ko update karein\n",
    "            \n",
    "            k = self.encoder_k(im_k) # Shape: [B, dim]\n",
    "            k = F.normalize(k, dim=1) # Normalize\n",
    "\n",
    "        # 3. Positive logits calculate karein (query vs positive key)\n",
    "        l_pos = (q * k).sum(dim=1).unsqueeze(-1) # Shape: [B, 1]\n",
    "\n",
    "        # 4. Negative logits calculate karein (query vs negative keys in queue)\n",
    "        l_neg = torch.matmul(q, self.queue.clone().detach()) # Shape: [B, K]\n",
    "\n",
    "        # 5. Logits ko milayein (Positive sample pehle)\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1) # Shape: [B, 1+K]\n",
    "\n",
    "        # 6. Temperature scale karein\n",
    "        logits /= self.T\n",
    "\n",
    "        # 7. Labels banayein (pehla sample [index 0] hamesha positive hota hai)\n",
    "        labels = torch.zeros(logits.shape[0], dtype=torch.long).to(q.device)\n",
    "        \n",
    "        # 8. Current batch ke keys ko queue mein daalein\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        return logits, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01e32450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.856387Z",
     "iopub.status.busy": "2025-10-26T20:50:14.856123Z",
     "iopub.status.idle": "2025-10-26T20:50:14.918062Z",
     "shell.execute_reply": "2025-10-26T20:50:14.917499Z"
    },
    "papermill": {
     "duration": 0.066453,
     "end_time": "2025-10-26T20:50:14.919066",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.852613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "PATIENCE = 5\n",
    "PROJECTION_DIM = 128\n",
    "LEARNING_RATE = 1e-4 # MoCo ke liye learning rate different ho sakti hai\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# MoCo-specific parameters\n",
    "QUEUE_SIZE = 4096   # Negative samples ka size (Batch size se bada)\n",
    "MOMENTUM = 0.999    # Momentum encoder ke liye\n",
    "TEMPERATURE = 0.07  # MoCo mein yeh common hai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64d1b34c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:14.926115Z",
     "iopub.status.busy": "2025-10-26T20:50:14.925900Z",
     "iopub.status.idle": "2025-10-26T20:50:16.868065Z",
     "shell.execute_reply": "2025-10-26T20:50:16.867455Z"
    },
    "papermill": {
     "duration": 1.947223,
     "end_time": "2025-10-26T20:50:16.869486",
     "exception": false,
     "start_time": "2025-10-26T20:50:14.922263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 227MB/s]\n"
     ]
    }
   ],
   "source": [
    "# 1. Model initialize karein\n",
    "model = MoCo(\n",
    "    base_encoder_cls=EncoderProjector,\n",
    "    dim=PROJECTION_DIM,\n",
    "    K=QUEUE_SIZE,\n",
    "    m=MOMENTUM,\n",
    "    T=TEMPERATURE\n",
    ").to(DEVICE)\n",
    "\n",
    "# 2. Loss function (Siraf CrossEntropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 3. Optimizer\n",
    "# Note: Hum sirf 'encoder_q' ke parameters optimize karte hain\n",
    "# 'encoder_k' momentum se update hota hai\n",
    "optimizer = optim.Adam(model.encoder_q.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e97f478",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:16.877914Z",
     "iopub.status.busy": "2025-10-26T20:50:16.877425Z",
     "iopub.status.idle": "2025-10-26T20:50:16.880827Z",
     "shell.execute_reply": "2025-10-26T20:50:16.880263Z"
    },
    "papermill": {
     "duration": 0.008442,
     "end_time": "2025-10-26T20:50:16.881801",
     "exception": false,
     "start_time": "2025-10-26T20:50:16.873359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "epoch_no_improve = 0\n",
    "best_val_loss = np.inf\n",
    "best_model_path = \"moco_encoder_best.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc90cac9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-26T20:50:16.889883Z",
     "iopub.status.busy": "2025-10-26T20:50:16.889691Z",
     "iopub.status.idle": "2025-10-26T22:51:55.647692Z",
     "shell.execute_reply": "2025-10-26T22:51:55.646570Z"
    },
    "papermill": {
     "duration": 7298.763835,
     "end_time": "2025-10-26T22:51:55.649075",
     "exception": false,
     "start_time": "2025-10-26T20:50:16.885240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19/3735282835.py:1: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "Epoch 1 (Train): 100%|██████████| 35/35 [02:33<00:00,  4.38s/it]\n",
      "Epoch 1 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 Complete.\n",
      "Avg Train Loss: 5.1426 | Avg Val Loss: 5.5059\n",
      "Validation loss improved (inf --> 5.5059). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2 (Train): 100%|██████████| 35/35 [02:30<00:00,  4.29s/it]\n",
      "Epoch 2 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100 Complete.\n",
      "Avg Train Loss: 5.9090 | Avg Val Loss: 5.7847\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3 (Train): 100%|██████████| 35/35 [02:27<00:00,  4.21s/it]\n",
      "Epoch 3 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100 Complete.\n",
      "Avg Train Loss: 5.7247 | Avg Val Loss: 5.4854\n",
      "Validation loss improved (5.5059 --> 5.4854). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 (Train): 100%|██████████| 35/35 [02:33<00:00,  4.38s/it]\n",
      "Epoch 4 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100 Complete.\n",
      "Avg Train Loss: 5.4130 | Avg Val Loss: 5.2266\n",
      "Validation loss improved (5.4854 --> 5.2266). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5 (Train): 100%|██████████| 35/35 [02:38<00:00,  4.52s/it]\n",
      "Epoch 5 (Val): 100%|██████████| 3/3 [00:18<00:00,  6.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100 Complete.\n",
      "Avg Train Loss: 5.1587 | Avg Val Loss: 4.8092\n",
      "Validation loss improved (5.2266 --> 4.8092). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6 (Train): 100%|██████████| 35/35 [02:36<00:00,  4.46s/it]\n",
      "Epoch 6 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100 Complete.\n",
      "Avg Train Loss: 4.8181 | Avg Val Loss: 4.6284\n",
      "Validation loss improved (4.8092 --> 4.6284). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7 (Train): 100%|██████████| 35/35 [02:36<00:00,  4.46s/it]\n",
      "Epoch 7 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100 Complete.\n",
      "Avg Train Loss: 4.6075 | Avg Val Loss: 4.4679\n",
      "Validation loss improved (4.6284 --> 4.4679). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8 (Train): 100%|██████████| 35/35 [02:39<00:00,  4.55s/it]\n",
      "Epoch 8 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100 Complete.\n",
      "Avg Train Loss: 4.4210 | Avg Val Loss: 4.2661\n",
      "Validation loss improved (4.4679 --> 4.2661). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9 (Train): 100%|██████████| 35/35 [02:34<00:00,  4.41s/it]\n",
      "Epoch 9 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100 Complete.\n",
      "Avg Train Loss: 4.1582 | Avg Val Loss: 3.9104\n",
      "Validation loss improved (4.2661 --> 3.9104). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10 (Train): 100%|██████████| 35/35 [02:37<00:00,  4.51s/it]\n",
      "Epoch 10 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100 Complete.\n",
      "Avg Train Loss: 3.9904 | Avg Val Loss: 3.8586\n",
      "Validation loss improved (3.9104 --> 3.8586). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11 (Train): 100%|██████████| 35/35 [02:39<00:00,  4.54s/it]\n",
      "Epoch 11 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.66s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100 Complete.\n",
      "Avg Train Loss: 3.6882 | Avg Val Loss: 3.7131\n",
      "Validation loss improved (3.8586 --> 3.7131). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12 (Train): 100%|██████████| 35/35 [02:34<00:00,  4.42s/it]\n",
      "Epoch 12 (Val): 100%|██████████| 3/3 [00:17<00:00,  5.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100 Complete.\n",
      "Avg Train Loss: 3.5102 | Avg Val Loss: 3.5455\n",
      "Validation loss improved (3.7131 --> 3.5455). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13 (Train): 100%|██████████| 35/35 [02:37<00:00,  4.49s/it]\n",
      "Epoch 13 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100 Complete.\n",
      "Avg Train Loss: 3.3663 | Avg Val Loss: 3.5235\n",
      "Validation loss improved (3.5455 --> 3.5235). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14 (Train): 100%|██████████| 35/35 [02:32<00:00,  4.37s/it]\n",
      "Epoch 14 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100 Complete.\n",
      "Avg Train Loss: 3.1486 | Avg Val Loss: 3.2312\n",
      "Validation loss improved (3.5235 --> 3.2312). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15 (Train): 100%|██████████| 35/35 [02:33<00:00,  4.38s/it]\n",
      "Epoch 15 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100 Complete.\n",
      "Avg Train Loss: 2.9625 | Avg Val Loss: 3.1398\n",
      "Validation loss improved (3.2312 --> 3.1398). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16 (Train): 100%|██████████| 35/35 [02:35<00:00,  4.44s/it]\n",
      "Epoch 16 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100 Complete.\n",
      "Avg Train Loss: 2.8546 | Avg Val Loss: 2.8190\n",
      "Validation loss improved (3.1398 --> 2.8190). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17 (Train): 100%|██████████| 35/35 [02:37<00:00,  4.50s/it]\n",
      "Epoch 17 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100 Complete.\n",
      "Avg Train Loss: 2.7084 | Avg Val Loss: 2.8550\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18 (Train): 100%|██████████| 35/35 [02:42<00:00,  4.63s/it]\n",
      "Epoch 18 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100 Complete.\n",
      "Avg Train Loss: 2.5436 | Avg Val Loss: 2.7942\n",
      "Validation loss improved (2.8190 --> 2.7942). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 (Train): 100%|██████████| 35/35 [02:35<00:00,  4.45s/it]\n",
      "Epoch 19 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100 Complete.\n",
      "Avg Train Loss: 2.4114 | Avg Val Loss: 2.5584\n",
      "Validation loss improved (2.7942 --> 2.5584). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20 (Train): 100%|██████████| 35/35 [02:39<00:00,  4.57s/it]\n",
      "Epoch 20 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100 Complete.\n",
      "Avg Train Loss: 2.3018 | Avg Val Loss: 2.5229\n",
      "Validation loss improved (2.5584 --> 2.5229). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21 (Train): 100%|██████████| 35/35 [02:41<00:00,  4.62s/it]\n",
      "Epoch 21 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100 Complete.\n",
      "Avg Train Loss: 2.1995 | Avg Val Loss: 2.3943\n",
      "Validation loss improved (2.5229 --> 2.3943). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22 (Train): 100%|██████████| 35/35 [02:42<00:00,  4.64s/it]\n",
      "Epoch 22 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100 Complete.\n",
      "Avg Train Loss: 2.0845 | Avg Val Loss: 2.5235\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23 (Train): 100%|██████████| 35/35 [02:31<00:00,  4.34s/it]\n",
      "Epoch 23 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100 Complete.\n",
      "Avg Train Loss: 1.9924 | Avg Val Loss: 2.1040\n",
      "Validation loss improved (2.3943 --> 2.1040). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24 (Train): 100%|██████████| 35/35 [02:33<00:00,  4.40s/it]\n",
      "Epoch 24 (Val): 100%|██████████| 3/3 [00:17<00:00,  5.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100 Complete.\n",
      "Avg Train Loss: 1.9000 | Avg Val Loss: 2.1612\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25 (Train): 100%|██████████| 35/35 [02:39<00:00,  4.56s/it]\n",
      "Epoch 25 (Val): 100%|██████████| 3/3 [00:17<00:00,  5.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100 Complete.\n",
      "Avg Train Loss: 1.8403 | Avg Val Loss: 2.1403\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26 (Train): 100%|██████████| 35/35 [02:41<00:00,  4.61s/it]\n",
      "Epoch 26 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100 Complete.\n",
      "Avg Train Loss: 1.7837 | Avg Val Loss: 2.0149\n",
      "Validation loss improved (2.1040 --> 2.0149). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27 (Train): 100%|██████████| 35/35 [02:39<00:00,  4.55s/it]\n",
      "Epoch 27 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100 Complete.\n",
      "Avg Train Loss: 1.6806 | Avg Val Loss: 2.0028\n",
      "Validation loss improved (2.0149 --> 2.0028). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28 (Train): 100%|██████████| 35/35 [02:40<00:00,  4.60s/it]\n",
      "Epoch 28 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100 Complete.\n",
      "Avg Train Loss: 1.6242 | Avg Val Loss: 1.9237\n",
      "Validation loss improved (2.0028 --> 1.9237). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29 (Train): 100%|██████████| 35/35 [02:33<00:00,  4.40s/it]\n",
      "Epoch 29 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100 Complete.\n",
      "Avg Train Loss: 1.5903 | Avg Val Loss: 1.9410\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30 (Train): 100%|██████████| 35/35 [02:30<00:00,  4.29s/it]\n",
      "Epoch 30 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100 Complete.\n",
      "Avg Train Loss: 1.5104 | Avg Val Loss: 1.7565\n",
      "Validation loss improved (1.9237 --> 1.7565). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31 (Train): 100%|██████████| 35/35 [02:29<00:00,  4.28s/it]\n",
      "Epoch 31 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100 Complete.\n",
      "Avg Train Loss: 1.4859 | Avg Val Loss: 1.8321\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32 (Train): 100%|██████████| 35/35 [02:32<00:00,  4.34s/it]\n",
      "Epoch 32 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100 Complete.\n",
      "Avg Train Loss: 1.4525 | Avg Val Loss: 1.6993\n",
      "Validation loss improved (1.7565 --> 1.6993). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33 (Train): 100%|██████████| 35/35 [02:28<00:00,  4.25s/it]\n",
      "Epoch 33 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100 Complete.\n",
      "Avg Train Loss: 1.3760 | Avg Val Loss: 1.7029\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34 (Train): 100%|██████████| 35/35 [02:31<00:00,  4.32s/it]\n",
      "Epoch 34 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100 Complete.\n",
      "Avg Train Loss: 1.3765 | Avg Val Loss: 1.6696\n",
      "Validation loss improved (1.6993 --> 1.6696). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35 (Train): 100%|██████████| 35/35 [02:32<00:00,  4.35s/it]\n",
      "Epoch 35 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100 Complete.\n",
      "Avg Train Loss: 1.3293 | Avg Val Loss: 1.6109\n",
      "Validation loss improved (1.6696 --> 1.6109). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36 (Train): 100%|██████████| 35/35 [02:25<00:00,  4.14s/it]\n",
      "Epoch 36 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100 Complete.\n",
      "Avg Train Loss: 1.3012 | Avg Val Loss: 1.5708\n",
      "Validation loss improved (1.6109 --> 1.5708). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37 (Train): 100%|██████████| 35/35 [02:27<00:00,  4.20s/it]\n",
      "Epoch 37 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100 Complete.\n",
      "Avg Train Loss: 1.2968 | Avg Val Loss: 1.4782\n",
      "Validation loss improved (1.5708 --> 1.4782). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38 (Train): 100%|██████████| 35/35 [02:25<00:00,  4.15s/it]\n",
      "Epoch 38 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100 Complete.\n",
      "Avg Train Loss: 1.2359 | Avg Val Loss: 1.3816\n",
      "Validation loss improved (1.4782 --> 1.3816). Saving model...\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39 (Train): 100%|██████████| 35/35 [02:25<00:00,  4.15s/it]\n",
      "Epoch 39 (Val): 100%|██████████| 3/3 [00:14<00:00,  4.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100 Complete.\n",
      "Avg Train Loss: 1.2151 | Avg Val Loss: 1.4826\n",
      "No improvement in validation loss for 1 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40 (Train): 100%|██████████| 35/35 [02:25<00:00,  4.17s/it]\n",
      "Epoch 40 (Val): 100%|██████████| 3/3 [00:15<00:00,  5.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100 Complete.\n",
      "Avg Train Loss: 1.2008 | Avg Val Loss: 1.4725\n",
      "No improvement in validation loss for 2 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41 (Train): 100%|██████████| 35/35 [02:21<00:00,  4.06s/it]\n",
      "Epoch 41 (Val): 100%|██████████| 3/3 [00:16<00:00,  5.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100 Complete.\n",
      "Avg Train Loss: 1.1831 | Avg Val Loss: 1.3941\n",
      "No improvement in validation loss for 3 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42 (Train): 100%|██████████| 35/35 [02:16<00:00,  3.90s/it]\n",
      "Epoch 42 (Val): 100%|██████████| 3/3 [00:14<00:00,  4.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100 Complete.\n",
      "Avg Train Loss: 1.1714 | Avg Val Loss: 1.5195\n",
      "No improvement in validation loss for 4 epoch(s).\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43 (Train): 100%|██████████| 35/35 [02:21<00:00,  4.06s/it]\n",
      "Epoch 43 (Val): 100%|██████████| 3/3 [00:14<00:00,  4.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100 Complete.\n",
      "Avg Train Loss: 1.1315 | Avg Val Loss: 1.4299\n",
      "No improvement in validation loss for 5 epoch(s).\n",
      "Early stopping triggered after 43 epochs.\n",
      "Training finished.\n",
      "Best model saved to moco_encoder_best.pth with validation loss: 1.3816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "try:\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for (views_1, views_2) in tqdm(train_loader, desc=f\"Epoch {epoch+1} (Train)\"):\n",
    "            im_q = views_1.to(DEVICE) # Query images\n",
    "            im_k = views_2.to(DEVICE) # Key images\n",
    "            \n",
    "            # Forward pass\n",
    "            # Model ab 'logits' aur 'labels' return karega\n",
    "            with torch.amp.autocast(DEVICE):\n",
    "                logits, labels = model(im_q, im_k)\n",
    "                # Loss calculate karein\n",
    "                loss = criterion(logits, labels)\n",
    "            \n",
    "            # Backward pass aur optimization\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            \n",
    "        # --- Ek Epoch poora ho gaya ---\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for (views_1, views_2) in tqdm(val_loader, desc=f\"Epoch {epoch+1} (Val)\"):\n",
    "                im_q = views_1.to(DEVICE)\n",
    "                im_k = views_2.to(DEVICE)\n",
    "\n",
    "                with torch.amp.autocast(DEVICE):\n",
    "                    logits, labels = model(im_q, im_k)\n",
    "                    loss = criterion(logits, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{NUM_EPOCHS} Complete.\")\n",
    "        print(f\"Avg Train Loss: {avg_train_loss:.4f} | Avg Val Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            print(f\"Validation loss improved ({best_val_loss:.4f} --> {avg_val_loss:.4f}). Saving model...\")\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            # Behtareen model ko save karein\n",
    "            torch.save(model.encoder_q.encoder.state_dict(), best_model_path)\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement in validation loss for {epochs_no_improve} epoch(s).\")\n",
    "        \n",
    "        if epochs_no_improve >= PATIENCE:\n",
    "            print(f\"Early stopping triggered after {epoch+1} epochs.\")\n",
    "            break\n",
    "        \n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "    # --- Saari training poori ho gayi ---\n",
    "    print(\"Training finished.\")\n",
    "    print(f\"Best model saved to {best_model_path} with validation loss: {best_val_loss:.4f}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during training step: {e}\")\n",
    "    if 'cuda' in str(e).lower():\n",
    "        print(\"Hint: Agar CUDA out of memory hai, to BATCH_SIZE kam karein.\") "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 8564390,
     "sourceId": 13489214,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7316.904506,
   "end_time": "2025-10-26T22:51:58.983254",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-26T20:50:02.078748",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
